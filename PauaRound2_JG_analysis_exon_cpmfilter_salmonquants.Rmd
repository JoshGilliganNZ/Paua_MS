---
title: "Paua_JG"
output: html_document
date: "2025-08-25"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(
  echo = TRUE,
  fig.path = "",
  dev = "png",
  dpi = 150,
  cache = FALSE
)

knitr::opts_knit$set(root.dir = "/projects/health_sciences/bms/biochemistry/kenny_group/1.Lincoln_Genomics_16th_Spetember_2025")

```



```{r setup, include=FALSE}
```

# BulkRNAseq pipeline
## This is based off of Marys DERNAseq

```{r Install packages, message=FALSE, warning=FALSE, collapse=T, include=FALSE}
# Set library path
.libPaths("/projects/health_sciences/bms/biochemistry/kenny_group/jgilligan")

.libPaths()
BiocManager::install("pheatmap")

BiocManager::install("DESeq2")
if (!require("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
install.packages("enrichplot")
if (!require("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
install.packages("gplots")
if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
BiocManager::install("DESeq2")
install.packages("extrafont")
install.packages("showtext")
BiocManager::install("ComplexHeatmap")
BiocManager::install("topGO")
install.packages("viridis") 
if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
BiocManager::install("vsn")
if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
BiocManager::install("genefilter")
install.packages("cowplot")
install.packages("ggplot2")
install.packages("viridis")
install.packages("ggVennDiagram") # if not installed
BiocManager::install("tximport")
install.packages("ggplot2")

```


```{r}
# pick a user-writeable lib (change the versioned path if needed)
user_lib <- Sys.getenv("R_LIBS_USER")
if (!dir.exists(user_lib)) dir.create(user_lib, recursive = TRUE, showWarnings = FALSE)

if (!requireNamespace("BiocManager", quietly = TRUE)) install.packages("BiocManager", lib = user_lib)
BiocManager::install("apeglm", update = FALSE, ask = FALSE, lib = user_lib)

```
### Loading libraries

```{r Loading libraries, message=FALSE, warning=FALSE, collapse=T, include=FALSE}
library(tidyverse); packageVersion("tidyverse")
library(readr); packageVersion("readr")
library(data.table); packageVersion("data.table")
library("RColorBrewer")
library("DESeq2")
library(ggplot2)
require(GO.db)
library("stringr")
library("forcats")
library("RColorBrewer")
library(dplyr)
library(pheatmap)
library(readr)
library(DESeq2)
library(ggplot2)
#library(cowplot)
library(viridis)
library(dplyr)
library(ggVennDiagram)
library(viridisLite)
library(tximport)
library(DESeq2)
suppressPackageStartupMessages({
  library(tximport)
  library(DESeq2)
  library(jsonlite)
})
suppressPackageStartupMessages({
  library(DESeq2)
  library(ggplot2)
})

library(apeglm)  # load it
library(tximport)
library(jsonlite)
library(tximport)
library(jsonlite)
library(data.table)
library(tximport)
library(dplyr)
library(tidyr)
library(ggplot2)
library(dplyr)
library(ggplot2)
library(scales)
library(jsonlite)
library(DESeq2)
library(dplyr)
library(ggplot2)
suppressPackageStartupMessages({
  library(ggplot2)
  library(dplyr)
})
suppressPackageStartupMessages({
  library(ggplot2); library(dplyr); library(tidyr)
})
suppressPackageStartupMessages({
  library(pheatmap)
})
setwd("/projects/health_sciences/bms/biochemistry/kenny_group/1.Lincoln_Genomics_16th_Spetember_2025")
getwd()
```



```{r}

coldata <- read.table('/projects/health_sciences/bms/biochemistry/kenny_group/Roseanna/Paua_sprng2024_sumr2025/Josh_test/paua_spring2024_summer2025.csv', sep = '\t', header = TRUE, check.names = FALSE)
if (is.null(rownames(coldata))) {
  rownames(coldata) <- coldata[[1]]
}
# 1) Find all quant.sf files
files_vec <- Sys.glob("Paua_salmon_mapping_round2/*P*/quant.sf")
#stopifnot(length(files_vec) == 60)  # expect 60 samples

# 2) Derive sample folder names (e.g., "L01_AP301C_74")
sample_dirs <- basename(dirname(files_vec))

# 3) Clean to SampleID used in your coldata (e.g., "AP301C")
sample_ids <- sub("_[0-9]+$", "", sub("^L\\d+_", "", sample_dirs))

# 4) Build a samples data.frame
samples <- data.frame(
  SampleID   = sample_ids,
  quant_path = files_vec,
  stringsAsFactors = FALSE
)

# Optional: bring in your existing coldata metadata by SampleID
stopifnot("SampleID" %in% names(coldata))
rownames(coldata) <- coldata$SampleID

# Merge: keep only samples present in both places
samples <- merge(samples, coldata, by = "SampleID", all.x = TRUE, sort = FALSE)

# Make sure ordering of 'files' matches SampleID exactly
files <- setNames(samples$quant_path, samples$SampleID)

# Sanity checks
stopifnot(!any(duplicated(names(files))))
stopifnot(all(names(files) %in% rownames(coldata)))


```


```{r}
# Peek one quant.sf to get transcript IDs
q0 <- read.delim(files[1], sep="\t", header=TRUE, check.names = FALSE)
stopifnot("Name" %in% names(q0))  # 'Name' column = transcript ID

# Trinity tx2gene: strip the isoform suffix `_iNN` to get the gene
tx2gene <- data.frame(
  TXNAME = q0$Name,
  GENEID = sub("_i\\d+$", "", q0$Name),
  stringsAsFactors = FALSE
)
# Deduplicate in case the first sample didn’t include all transcripts
tx2gene <- unique(tx2gene)

```


```{r}
# Import Salmon quantifications; lengthScaledTPM is a solid default for gene-level DE
txi <- tximport(files,
                type = "salmon",
                tx2gene = tx2gene,
                ignoreTxVersion = TRUE,
                countsFromAbundance = "lengthScaledTPM")


# Align colData to txi columns
stopifnot(all(colnames(txi$counts) %in% samples$SampleID))
cd <- samples[match(colnames(txi$counts), samples$SampleID), , drop = FALSE]
rownames(cd) <- cd$SampleID

# Factors (ordered heatwave levels)
cd$Location <- factor(cd$Location)
cd$before_during_heatwave <- factor(cd$before_during_heatwave, levels = c("Before","During"))

# Build DESeq2 object with just these terms
dds <- DESeqDataSetFromTximport(
  txi,
  colData = cd,
  design  = ~ Location + before_during_heatwave
)

# (Optional) drop all-zero genes
dds <- dds[rowSums(counts(dds)) > 0, ]

# VST for PCA
vsd <- vst(dds, blind = TRUE)

# PCA
pcaData <- plotPCA(vsd, intgroup = c("before_during_heatwave","Location"), returnData = TRUE)
percentVar <- round(100 * attr(pcaData, "percentVar"))

ggplot(pcaData, aes(PC1, PC2,
                    color = before_during_heatwave,
                    shape = Location)) +
  geom_point(size = 3, alpha = 0.85) +
  xlab(paste0("PC1: ", percentVar[1], "% variance")) +
  ylab(paste0("PC2: ", percentVar[2], "% variance")) +
  theme_classic() +
  theme(legend.position = "right", text = element_text(size = 12))
```
```{r}
# library size distribution
colSums(counts(dds))

# sample-wise count distributions
boxplot(log10(counts(dds)+1), las=2)
```


```{r}
# ----- Packages -----
# Build a samples table keyed by SampleID
samples <- data.frame(
  SampleID   = sample_ids,
  quant_path = files_vec,
  stringsAsFactors = FALSE
)

# Ensure coldata is keyed by SampleID and align
stopifnot("SampleID" %in% names(coldata))
rownames(coldata) <- trimws(as.character(coldata$SampleID))

# Merge metadata
samples <- merge(samples, coldata, by = "SampleID", all.x = TRUE, sort = FALSE)
rownames(samples) <- samples$SampleID

# Build named vector for tximport (names MUST be SampleID)
files <- setNames(samples$quant_path, samples$SampleID)
stopifnot(!any(duplicated(names(files))))

# =========================================
# 2) Build tx2gene (Trinity: strip `_iNN`)
# =========================================
# (Union over all samples to be robust)
get_tx2gene_from_quant <- function(f) {
  q <- read.delim(f, sep = "\t", header = TRUE, check.names = FALSE, colClasses = c(Name="character"))
  data.frame(TXNAME = q$Name,
             GENEID = sub("_i\\d+$", "", q$Name),
             stringsAsFactors = FALSE)
}
tx2gene <- unique(do.call(rbind, lapply(files, get_tx2gene_from_quant)))

# ==============================================
# 3) tximport (countsFromAbundance = "no" for CPM)
# ==============================================
txi <- tximport(files,
                type = "salmon",
                tx2gene = tx2gene,
                ignoreTxVersion = TRUE,
                countsFromAbundance = "no")  # use raw estimated counts => CPM makes sense

# ==========================================================
# 4) Drop low-depth samples using Salmon num_mapped < 1e6
# ==========================================================
# Map each file to its quant directory
quant_dirs <- dirname(files)

get_num_mapped <- function(qdir) {
  mi_path <- file.path(qdir, "aux_info", "meta_info.json")
  if (!file.exists(mi_path)) return(NA_real_)
  mi <- jsonlite::fromJSON(mi_path)
  if (!is.null(mi$num_mapped)) return(as.numeric(mi$num_mapped))
  if (!is.null(mi$num_processed)) return(as.numeric(mi$num_processed))
  NA_real_
}

num_mapped <- vapply(quant_dirs, get_num_mapped, numeric(1))
names(num_mapped) <- names(files)

low_depth <- names(num_mapped[!is.na(num_mapped) & num_mapped < 1e6])
if (length(low_depth)) {
  message("Dropping low-depth samples (<1M mapped fragments): ",
          paste(low_depth, collapse = ", "))
}

keep_samps <- setdiff(colnames(txi$counts), low_depth)
if (!length(keep_samps)) stop("All samples were filtered; adjust the 1e6 threshold.")

# Filter txi matrices and metadata
txi$counts    <- txi$counts[, keep_samps, drop = FALSE]
txi$abundance <- txi$abundance[, keep_samps, drop = FALSE]
txi$length    <- txi$length[, keep_samps, drop = FALSE]
samples       <- samples[keep_samps, , drop = FALSE]

# Sanity
stopifnot(identical(colnames(txi$counts), rownames(samples)))

# ======================================
# 5) CPM calculation and gene filtering
# ======================================
# CPM = counts / library_size * 1e6 (library_size = colSums of counts matrix)
lib_sizes <- colSums(txi$counts)
cpm_mat   <- t( t(txi$counts) / lib_sizes * 1e6 )

# Choose k = smallest group size among analysis factors
if ("before_during_heatwave" %in% names(samples)) {
  k <- max(3L, min(table(samples$before_during_heatwave)))
} else if ("Location" %in% names(samples)) {
  k <- max(3L, min(table(samples$Location)))
} else {
  k <- 5L
}

keep_genes <- rowSums(cpm_mat >= 1) >= k
counts_filtered <- txi$counts[keep_genes, , drop = FALSE]

message(sprintf("Retained %s genes out of %s (CPM ≥ 1 in ≥ %s samples).",
                format(nrow(counts_filtered), big.mark = ","),
                format(nrow(txi$counts),       big.mark = ","),
                k))

# Align coldata for downstream DESeq2, PCA, etc.
coldata <- samples[colnames(counts_filtered), , drop = FALSE]
stopifnot(identical(colnames(counts_filtered), rownames(coldata)))

```



```{r}
# after running tximport
saveRDS(txi, file = "txi_salmon_lengthScaledTPM.rds")
getwd()  # shows where R is writing
list.files(getwd(), pattern = "txi_salmon")
# later, reload in a fresh session
txi <- readRDS("txi_salmon_lengthScaledTPM.rds")
#head(txi)
```


```{r}
# ---- 0) Ensure we have a VST matrix ----
# If you already have 'vsd', this will be skipped.
if (!exists("vsd")) {
  stopifnot(exists("counts_filtered"), exists("coldata"))
  stopifnot(identical(colnames(counts_filtered), rownames(coldata)))
  dds <- DESeqDataSetFromMatrix(
    countData = counts_filtered,
    colData   = transform(coldata, before_during_heatwave = factor(before_during_heatwave, levels = c("Before","During"),
                                                                   ordered = FALSE)),
    design    = ~ Location + before_during_heatwave
  )
  vsd <- vst(dds, blind = TRUE)
}

# ---- 1) PCA on ALL genes (match plotPCA centering) ----
mat <- assay(vsd)                      # genes x samples

# Drop zero-variance genes (required for PCA)
rv <- apply(mat, 1, var)
mat <- mat[rv > 0, , drop = FALSE]

# Center each gene (row) to mean 0 across samples (as plotPCA does)
mat_centered <- mat - rowMeans(mat)

# Run PCA on samples (transpose so samples are rows)
pca <- prcomp(t(mat_centered), center = FALSE, scale. = FALSE)

# % variance explained
percentVar <- (pca$sdev^2) / sum(pca$sdev^2) * 100

# Scores + metadata
scores <- as.data.frame(pca$x)         # rows = samples, columns = PC1, PC2, ...
scores$SampleID <- rownames(scores)
# add any metadata you want for coloring/shaping
meta_cols <- intersect(c("Location","before_during_heatwave","Lane","Date","length_mm"), colnames(coldata))
scores <- cbind(scores, coldata[rownames(scores), meta_cols, drop = FALSE])

# ---- 2) Helper to plot any PC pair quickly ----
plot_pc <- function(pc_x = 1, pc_y = 2, color_by = "before_during_heatwave", shape_by = "Location") {
  stopifnot(pc_x >= 1, pc_y >= 1, pc_x <= ncol(pca$x), pc_y <= ncol(pca$x))
  aes_cols <- c(color_by, shape_by)
  aes_cols <- aes_cols[aes_cols %in% names(scores)]
  g <- ggplot(scores, aes_string(x = paste0("PC", pc_x), y = paste0("PC", pc_y),
                                 color = if ("before_during_heatwave" %in% aes_cols) color_by else aes_cols[1],
                                 shape = if ("Location" %in% aes_cols) shape_by else NA)) +
    geom_point(size = 3, alpha = 0.85) +
    labs(
      title = sprintf("PCA (all genes): PC%d vs PC%d", pc_x, pc_y),
      x = sprintf("PC%d (%.1f%%)", pc_x, percentVar[pc_x]),
      y = sprintf("PC%d (%.1f%%)", pc_y, percentVar[pc_y])
    ) +
    theme_classic()
  if (!("Location" %in% aes_cols)) g <- g + guides(shape = "none")
  g
}

# Example: PC1 vs PC2
p12 <- plot_pc(1, 2)
print(p12)

# ---- 3) Grid of pairs for PC1–PC10 (1–2, 3–4, 5–6, 7–8, 9–10) ----
pairs_list <- list(
  plot_pc(1, 2),
  plot_pc(3, 4),
  plot_pc(5, 6),
  plot_pc(7, 8),
  plot_pc(9, 10)
)

# If you have patchwork installed, you can arrange them nicely:
if (requireNamespace("patchwork", quietly = TRUE)) {
  library(patchwork)
  print( (pairs_list[[1]] | pairs_list[[2]]) /
         (pairs_list[[3]] | pairs_list[[4]]) /
         (pairs_list[[5]]) )
}

# ---- 4) Scree plot for the first 10 PCs ----
scree_df <- data.frame(PC = seq_along(percentVar), VarExplained = percentVar)
ggplot(scree_df[1:min(10, nrow(scree_df)), ],
       aes(PC, VarExplained)) +
  geom_col() +
  geom_text(aes(label = sprintf("%.1f%%", VarExplained)), vjust = -0.3, size = 3) +
  labs(title = "Scree plot (first 10 PCs)", x = "Principal component", y = "% variance explained") +
  theme_classic()
```
##Merge with primary dataset

```{r}

coldata <- read.table('/projects/health_sciences/bms/biochemistry/kenny_group/Roseanna/Paua_sprng2024_sumr2025/Josh_test/paua_spring2024_summer2025.csv', sep = '\t', header = TRUE, check.names = FALSE)
if (is.null(rownames(coldata))) {
  rownames(coldata) <- coldata[[1]]
}


```



```{r}

# --- 0) (Optional) make sure r2 paths are absolute if you're knitting ----
r1_quant_paths <- Sys.glob("/projects/health_sciences/bms/biochemistry/kenny_group/Roseanna/Paua_sprng2024_sumr2025/Josh_test/Paua_salmon_mapping/*/quant.sf")
r2_quant_paths <- Sys.glob("/projects/health_sciences/bms/biochemistry/kenny_group/1.Lincoln_Genomics_16th_Spetember_2025/Paua_salmon_mapping_round2/*P*/quant.sf")
# ---- 1) Extract "full code" (e.g., AP402A) from folder names ----
r1_ids_raw <- basename(dirname(r1_quant_paths))
r2_ids_raw <- basename(dirname(r2_quant_paths))

extract_full <- function(x) sub("^[^_]+_([^_]+)_[^_]+$", "\\1", x)  # AP402A
r1_full <- extract_full(r1_ids_raw)
r2_full <- extract_full(r2_ids_raw)

# ---- 2) Count duplicates BEFORE merging (by full code) ---------------
tab_r1  <- sort(table(r1_full), decreasing = TRUE)
tab_r2  <- sort(table(r2_full), decreasing = TRUE)
tab_all <- sort(table(c(r1_full, r2_full)), decreasing = TRUE)

dups_r1   <- tab_r1[tab_r1 > 1]
dups_r2   <- tab_r2[tab_r2 > 1]
dups_both <- tab_all[tab_all > 1]

cat("Round 1: files =", length(r1_quant_paths), "| unique full codes =", length(unique(r1_full)), "\n")
cat("Round 2: files =", length(r2_quant_paths), "| unique full codes =", length(unique(r2_full)), "\n")
cat("Across both: total files =", length(r1_quant_paths) + length(r2_quant_paths),
    "| unique full codes =", length(unique(c(r1_full, r2_full))),
    "| duplicated codes =", length(dups_both), "\n\n")
```
```{r}

library(jsonlite)

if (length(dups_r1)) {
  cat("Within-round duplicates (R1):\n"); print(dups_r1)
} else cat("No within-round duplicates in R1.\n")
if (length(dups_r2)) {
  cat("Within-round duplicates (R2):\n"); print(dups_r2)
} else cat("No within-round duplicates in R2.\n")

if (length(dups_both)) {
  cat("\nDuplicates across rounds (full codes and their counts):\n")
  print(dups_both)
  cat("\nExamples of duplicated full codes:\n")
  print(utils::head(names(dups_both), 10))
}

# Optional: map which exact folders contribute to a given duplicated code
inspect_full_code <- function(code) {
  keep1 <- r1_full == code
  keep2 <- r2_full == code
  data.frame(
    Round    = c(rep("R1", sum(keep1)), rep("R2", sum(keep2))),
    Folder   = c(r1_ids_raw[keep1],     r2_ids_raw[keep2]),
    FullCode = c(r1_full[keep1],        r2_full[keep2]),
    Path     = c(r1_quant_paths[keep1], r2_quant_paths[keep2]),
    row.names = NULL, check.names = FALSE
  )
}
# Example:
# inspect_full_code("AP402A")

# ---- 3) Build files vector (names = full code), give unique names for import ----
files_r1 <- setNames(r1_quant_paths, r1_full)
files_r2 <- setNames(r2_quant_paths, r2_full)
files_all <- c(files_r1, files_r2)

true_keys  <- names(files_all)                 # full codes (may repeat)
uniq_names <- make.unique(true_keys, sep="__rep")
names(files_all) <- uniq_names
group_map <- setNames(true_keys, uniq_names)   # unique colname -> full code
`%||%` <- function(a,b) if (is.null(a)) b else a

# files_all is your named vector of quant.sf paths
qfiles <- unname(files_all)

get_hash <- function(f) {
  mi <- file.path(dirname(f), "aux_info", "meta_info.json")
  if (!file.exists(mi)) return(NA_character_)
  x <- jsonlite::fromJSON(mi)
  x$index_seq_hash %||% NA_character_
}

hashes <- vapply(qfiles, get_hash, character(1))
tbl <- sort(table(hashes), decreasing = TRUE)
print(tbl)  # <- This tells you how many distinct indices and how many files per index

```



```{r}

## 1) Build tx2gene from ONE representative file (since index hash is identical)
rep_file <- unname(files_all)[1]
txnames <- fread(rep_file, select = "Name", showProgress = TRUE)[["Name"]]
tx2gene <- data.frame(
  TXNAME = txnames,
  GENEID = sub("_i\\d+$", "", txnames),   # Trinity: strip transcript suffix
  stringsAsFactors = FALSE, check.names = FALSE
)

## (Optional) Save for reuse
# saveRDS(tx2gene, "tx2gene_trinity_from_indexhash.rds")

## 2) Import all 87 with additive counts
txi_all <- tximport(files_all, type = "salmon", tx2gene = tx2gene,
                    ignoreTxVersion = TRUE, countsFromAbundance = "no")

## 3) Collapse technical repeats by FULL code (sum counts; counts-weighted length)
collapse_txi_by_group <- function(txi, group_vec) {
  stopifnot(identical(names(group_vec), colnames(txi$counts)))
  final_ids <- unique(group_vec)

  counts_out <- matrix(0, nrow = nrow(txi$counts), ncol = length(final_ids),
                       dimnames = list(rownames(txi$counts), final_ids))
  length_out <- matrix(NA_real_, nrow = nrow(txi$counts), ncol = length(final_ids),
                       dimnames = list(rownames(txi$counts), final_ids))

  for (sid in final_ids) {
    idx <- which(group_vec == sid)
    C <- txi$counts[, idx, drop = FALSE]
    counts_out[, sid] <- rowSums(C, na.rm = TRUE)

    if (!is.null(txi$length)) {
      L <- txi$length[, idx, drop = FALSE]
      num <- rowSums(L * C, na.rm = TRUE)
      den <- rowSums(C,     na.rm = TRUE)
      length_out[, sid] <- ifelse(den > 0, num / den, NA_real_)
    }
  }

  # Recompute TPM (optional but nice to have)
  abundance_out <- NULL
  if (!is.null(length_out)) {
    rate <- counts_out / (length_out / 1000)
    rate[!is.finite(rate)] <- 0
    scale <- colSums(rate, na.rm = TRUE)
    abundance_out <- sweep(rate, 2, scale, "/") * 1e6
    abundance_out[!is.finite(abundance_out)] <- 0
  }

  list(counts = counts_out, abundance = abundance_out, length = length_out)
}

txi_merged <- collapse_txi_by_group(txi_all, group_map)
cat(sprintf("Merged to %d full-code samples from %d files.\n",
            ncol(txi_merged$counts), length(files_all)))

## 4) Global CPM filter (tune these two knobs)
lib_sizes <- colSums(txi_merged$counts)
cpm_mat   <- t( t(txi_merged$counts) / lib_sizes * 1e6 )

cpm_threshold <- 1      # <-- make stricter/looser, e.g. 0.5, 1, 2
min_samples   <- 5L     # <-- make stricter/looser, e.g. 3, 5, 8

keep_genes <- rowSums(cpm_mat >= cpm_threshold) >= min_samples
counts_filtered <- txi_merged$counts[keep_genes, , drop = FALSE]

message(sprintf("Retained %s/%s genes (CPM ≥ %s in ≥ %s merged samples).",
                format(nrow(counts_filtered), big.mark = ","),
                format(nrow(txi_merged$counts), big.mark = ","),
                cpm_threshold, min_samples))

## Examples:
# Looser:  cpm_threshold <- 0.5; min_samples <- 3L
# Stricter: cpm_threshold <- 2;   min_samples <- 8L


```

```{r}

# Tag each row by round using the path
merge_qc <- merge_qc %>%
  mutate(round = ifelse(grepl("Paua_salmon_mapping_round2", quant_path), "R2", "R1"))

# Sum per full_code × round, then compute within-key fractions
by_round <- merge_qc %>%
  group_by(full_code, round) %>%
  summarize(num_mapped = sum(num_mapped, na.rm = TRUE), .groups = "drop") %>%
  group_by(full_code) %>%
  mutate(total = sum(num_mapped, na.rm = TRUE),
         frac  = ifelse(total > 0, num_mapped / total, NA_real_)) %>%
  ungroup()

# Compute improvement (fraction R2 - fraction R1)
deltas <- by_round %>%
  select(full_code, round, frac) %>%
  pivot_wider(names_from = round, values_from = frac, values_fill = 0) %>%
  mutate(delta_R2_minus_R1 = coalesce(R2, 0) - coalesce(R1, 0))

# Pick the ones that "got better" (R2 share > R1 share)
improved <- deltas %>%
  filter(delta_R2_minus_R1 > 0) %>%
  arrange(desc(delta_R2_minus_R1))

# Choose how many to show
topN <- 27
keep_keys <- head(improved$full_code, topN)

plot_df <- by_round %>%
  filter(full_code %in% keep_keys) %>%
  mutate(full_code = factor(full_code, levels = keep_keys[order(match(keep_keys, improved$full_code))]))

# OPTION A: share-of-mapped (percent) bar, stacked and normalized
ggplot(plot_df, aes(x = full_code, y = frac, fill = round)) +
  geom_col(position = "fill") +
  coord_flip() +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  labs(title = "Technical repeats that improved in Round 2",
       subtitle = sprintf("Top %d by increase in Round 2 share of mapped fragments", topN),
       x = "Full code", y = "Share of mapped fragments") +
  theme_bw()

# OPTION B: absolute mapped fragments (stacked counts)
ggplot(plot_df, aes(x = full_code, y = num_mapped, fill = round)) +
  geom_col() +
  coord_flip() +
  scale_y_continuous(labels = scales::label_number(scale_cut = scales::cut_short_scale())) +
  labs(title = "Mapped fragments by round (top improved samples)",
       x = "Full code", y = "Mapped fragments") +
  theme_bw()


```
```{r}


# If you don't still have this:
get_num_mapped <- function(quant_file) {
  mi <- file.path(dirname(quant_file), "aux_info", "meta_info.json")
  if (!file.exists(mi)) return(NA_real_)
  x <- fromJSON(mi)
  if (!is.null(x$num_mapped)) return(as.numeric(x$num_mapped))
  if (!is.null(x$num_processed)) return(as.numeric(x$num_processed))
  NA_real_
}

# Build a per-file table for ALL files (87), not just duplicated keys
files_df <- data.frame(
  import_col = names(files_all),
  full_code  = unname(group_map[names(files_all)]),
  quant_path = unname(files_all),
  stringsAsFactors = FALSE, check.names = FALSE
) %>%
  mutate(
    round = ifelse(grepl("Paua_salmon_mapping_round2", quant_path), "R2", "R1"),
    num_mapped = vapply(quant_path, get_num_mapped, numeric(1))
  )

# A) One bar per merged sample (ALL 60): total mapped fragments
totals_merged <- files_df %>%
  group_by(full_code) %>%
  summarize(total_mapped = sum(num_mapped, na.rm = TRUE), .groups = "drop") %>%
  arrange(desc(total_mapped)) %>%
  mutate(full_code = factor(full_code, levels = full_code))

cat("Merged samples (should be 60):", nrow(totals_merged), "\n")

ggplot(totals_merged, aes(x = full_code, y = total_mapped)) +
  geom_col() +
  coord_flip() +
  scale_y_continuous(labels = label_number(scale_cut = cut_short_scale())) +
  labs(
    title = sprintf("Total mapped fragments per merged sample (n = %d)", nrow(totals_merged)),
    x = "Merged sample (full code)", y = "Mapped fragments"
  ) +
  theme_bw()

# B) Stacked by round (R1 vs R2) for ALL 60
by_round <- files_df %>%
  group_by(full_code, round) %>%
  summarize(num_mapped = sum(num_mapped, na.rm = TRUE), .groups = "drop") %>%
  group_by(full_code) %>%
  mutate(total_mapped = sum(num_mapped, na.rm = TRUE)) %>%
  ungroup() %>%
  mutate(full_code = factor(full_code, levels = levels(totals_merged$full_code)))

ggplot(by_round, aes(x = full_code, y = num_mapped, fill = round)) +
  geom_col() +
  coord_flip() +
  scale_y_continuous(labels = label_number(scale_cut = cut_short_scale())) +
  labs(
    title = "Mapped fragments per merged sample (stacked by round)",
    x = "Merged sample (full code)", y = "Mapped fragments"
  ) +
  theme_bw() +
  theme(legend.position = "top")


```
```{r}

# Save
saveRDS(txi_all, file = "paua_txi_all.rds")

# Load later
txi_all <- readRDS("paua_txi_all.rds")


```





```{r}

# counts_filtered: genes x merged samples (raw counts; CPM used only for filtering)
stopifnot(exists("counts_filtered"))

# ----- align colData to merged samples -----
# coldata should have IDs that match merged sample column names (full codes like AP402A)
# If your metadata has a sample column that looks like "L01_AP402A_12", derive the full code:
extract_full <- function(x) sub("^[^_]+_([^_]+)_[^_]+$", "\\1", x)

# Read your metadata (tab-delimited despite .csv suffix)
meta_path <- "/projects/health_sciences/bms/biochemistry/kenny_group/Roseanna/Paua_sprng2024_sumr2025/Josh_test/paua_spring2024_summer2025.csv"
coldata <- read.delim(meta_path, sep = "\t", header = TRUE, check.names = FALSE, stringsAsFactors = FALSE)

# Pick an ID column and normalize to FullCode that matches colnames(counts_filtered)
id_candidates <- c("FullCode","full_code","Full_Code","SampleID","sample_id","Sample")
id_col <- id_candidates[id_candidates %in% names(coldata)][1]
stopifnot(length(id_col) == 1)

ids <- coldata[[id_col]]
if (any(grepl("^L\\d+_[A-Z]{2}\\d{3}[A-Z]_\\d+$", ids))) ids <- extract_full(ids)
coldata$FullCode <- ids
rownames(coldata) <- coldata$FullCode

# Align to counts
cd <- coldata[colnames(counts_filtered), , drop = FALSE]
stopifnot(identical(rownames(cd), colnames(counts_filtered)))

# Factors (adjust to your design)
if ("Location" %in% names(cd)) cd$Location <- factor(cd$Location)
if ("before_during_heatwave" %in% names(cd)) {
  cd$before_during_heatwave <- factor(cd$before_during_heatwave, levels = c("Before","During"))
}

# ----- build DESeq2 dataset from RAW counts (filtered by CPM) -----
dds <- DESeqDataSetFromMatrix(
  countData = round(counts_filtered),          # DESeq2 expects integer counts
  colData   = cd,
  design    = ~ Location + before_during_heatwave
)

# (Optional) extra low-count prefilter (speeds up)
keep <- rowSums(counts(dds)) >= 10
dds <- dds[keep, ]

# Run DE
dds <- DESeq(dds)

# Example contrast: During vs Before (adjust to your factor names)
res <- results(dds, contrast = c("before_during_heatwave","During","Before"))
res <- lfcShrink(dds, coef = "before_during_heatwave_During_vs_Before", type = "apeglm")

# Quick QC plots
plotMA(res, ylim = c(-4,4))
vsd <- vst(dds, blind = TRUE)
pcaData <- plotPCA(vsd, intgroup = c("before_during_heatwave","Location"), returnData = TRUE)
percentVar <- round(100 * attr(pcaData, "percentVar"))
ggplot(pcaData, aes(PC1, PC2, color = before_during_heatwave, shape = Location)) +
  geom_point(size = 3, alpha = 0.85) +
  xlab(paste0("PC1: ", percentVar[1], "%")) +
  ylab(paste0("PC2: ", percentVar[2], "%")) +
  theme_classic()


```
```{r}
## 1) Subset to Akaroa
dds_ak <- dds[, dds$Location == "Akaroa"]
dds_ak$Location <- droplevels(dds_ak$Location)
dds_ak$before_during_heatwave     <- droplevels(dds_ak$before_during_heatwave)

## (optional) set design for this subset (not required for PCA)
design(dds_ak) <- ~ before_during_heatwave

## 2) VST on the subset
vsd_ak <- vst(dds_ak, blind = TRUE)

## 3) PCA (color by Date)
pcaData_ak <- plotPCA(vsd_ak, intgroup = "before_during_heatwave", returnData = TRUE)
percentVar <- round(100 * attr(pcaData_ak, "percentVar"))

ggplot(pcaData_ak, aes(PC1, PC2, color = before_during_heatwave)) +
  geom_point(size = 3) +
  xlab(paste0("PC1: ", percentVar[1], "% variance")) +
  ylab(paste0("PC2: ", percentVar[2], "% variance")) +
  theme_classic()


# --- your PCA helper (unchanged) ---
pca_by_location <- function(dds, loc, ntop = 500) {
  dds_sub <- dds[, dds$Location == loc]
  dds_sub$Location <- droplevels(dds_sub$Location)
  dds_sub$before_during_heatwave     <- droplevels(dds_sub$before_during_heatwave)

  vsd_sub <- vst(dds_sub, blind = TRUE)
  pdat    <- plotPCA(vsd_sub, intgroup = "before_during_heatwave", ntop = ntop, returnData = TRUE)
  pv      <- round(100 * attr(pdat, "percentVar"))

  p <- ggplot(pdat, aes(PC1, PC2, color = before_during_heatwave)) +
        geom_point(size = 3) +
        xlab(paste0("PC1: ", pv[1], "%")) +
        ylab(paste0("PC2: ", pv[2], "%")) +
        ggtitle(loc) +
        coord_equal() +
        theme_classic()

  list(data = pdat, plot = p)
}

# Run PCs
ak <- pca_by_location(dds, "Akaroa")
ha <- pca_by_location(dds, "Haast")
ka <- pca_by_location(dds, "Karitane")

# Shared axis limits
lims <- range(c(ak$data$PC1, ha$data$PC1, ka$data$PC1,
                ak$data$PC2, ha$data$PC2, ka$data$PC2))
ak_p <- ak$plot + xlim(lims) + ylim(lims)
ha_p <- ha$plot + xlim(lims) + ylim(lims)
ka_p <- ka$plot + xlim(lims) + ylim(lims)

# Extract a shared legend (from one plot)
legend <- cowplot::get_legend(ak_p + theme(legend.position = "right"))

# Remove legends from panels
ak_p2 <- ak_p + theme(legend.position = "none")
ha_p2 <- ha_p + theme(legend.position = "none")
ka_p2 <- ka_p + theme(legend.position = "none")

# Arrange three panels
row_panels <- cowplot::plot_grid(ak_p2, ha_p2, ka_p2, ncol = 3, align = "hv")

# Add legend to the right
combined <- cowplot::plot_grid(row_panels, legend, ncol = 2, rel_widths = c(1, 0.18))

# Show and save
print(combined)
ggsave("PCA_by_locationround2cpm.pdf", combined, width = 12, height = 4, limitsize = FALSE)
ak
ha
ka
```
```{r Correlation heatmap, echo=FALSE, message=FALSE, warning=FALSE, fig.width = 8, fig.height=6}
# Correlation matrix
mat <- assay(vsd)
vsd_cor <- cor(mat, method = "pearson")
samps <- colnames(vsd_cor)

# Annotation data frame
wanted_annos <- c("Location", "before_during_heatwave")
have_annos   <- intersect(wanted_annos, colnames(coldata))

anno <- as.data.frame(coldata[samps, have_annos, drop = FALSE])
rownames(anno) <- samps

# Ensure factors are properly set
for (col in have_annos) {
  anno[[col]] <- factor(anno[[col]])
}

# Helper for color palettes
mk_cols <- function(fct, palette) {
  lv <- levels(fct)
  cols <- rep_len(palette, length(lv))
  setNames(cols, lv)
}

# Annotation colors
annotation_colors <- list()
if ("Location" %in% colnames(anno)) {
  annotation_colors$Location <- mk_cols(
    anno$Location,
    c("cyan","yellow","magenta","orange","purple","green")
  )
}
if ("before_during_heatwave" %in% colnames(anno)) {
  annotation_colors$before_during_heatwave <- mk_cols(
    anno$before_during_heatwave,
    c("red","blue","grey60")
  )
}

# Heatmap
pheatmap(
  vsd_cor,
  annotation_col       = anno,
  annotation_colors    = annotation_colors,
  color                = viridis(255),
  border_color         = "black",
  cluster_rows         = TRUE,
  cluster_cols         = TRUE,
  show_rownames        = FALSE,
  show_colnames        = FALSE,
  main                 = "Sample–sample correlation (VST)",
  annotation_names_col = TRUE,
  fontsize             = 10,
  legend               = TRUE,
  legend_breaks        = seq(0.5, 1, 0.1),
  legend_labels        = seq(0.5, 1, 0.1),
  treeheight_col       = 20,
  treeheight_row       = 20
)
```
```{r}
# ---- Akaroa-only correlation heatmap (inline) ----
samps <- colnames(vsd)[colData(vsd)$Location == "Akaroa"]
mat   <- assay(vsd)[ , samps, drop = FALSE]
cor_ak <- cor(mat, method = "pearson")

anno_ak <- as.data.frame(colData(vsd)[samps, "before_during_heatwave", drop = FALSE])
for (nm in names(anno_ak)) anno_ak[[nm]] <- droplevels(factor(anno_ak[[nm]]))
stopifnot(identical(rownames(anno_ak), colnames(cor_ak)))

pheatmap::pheatmap(
  cor_ak,
  annotation_col    = anno_ak,
  color             = viridisLite::viridis(255),
  border_color      = "black",
  cluster_rows      = TRUE,
  cluster_cols      = TRUE,
  show_rownames     = FALSE,
  show_colnames     = FALSE,
  main              = sprintf("Akaroa — sample–sample correlation (n=%d)", length(samps)),
  legend            = TRUE
)
```
```{r}
# ---- haast-only correlation heatmap (inline) ----
samps <- colnames(vsd)[colData(vsd)$Location == "Haast"]
mat   <- assay(vsd)[ , samps, drop = FALSE]
cor_ha <- cor(mat, method = "pearson")

anno_ha <- as.data.frame(colData(vsd)[samps, "before_during_heatwave", drop = FALSE])
for (nm in names(anno_ha)) anno_ha[[nm]] <- droplevels(factor(anno_ha[[nm]]))
stopifnot(identical(rownames(anno_ha), colnames(cor_ha)))

pheatmap::pheatmap(
  cor_ha,
  annotation_col    = anno_ha,
  color             = viridisLite::viridis(255),
  border_color      = "black",
  cluster_rows      = TRUE,
  cluster_cols      = TRUE,
  show_rownames     = FALSE,
  show_colnames     = FALSE,
  main              = sprintf("haast — sample–sample correlation (n=%d)", length(samps)),
  legend            = TRUE
)
```
```{r}
# ---- karitane-only correlation heatmap (inline) ----
samps <- colnames(vsd)[colData(vsd)$Location == "Karitane"]
mat   <- assay(vsd)[ , samps, drop = FALSE]
cor_ka <- cor(mat, method = "pearson")

anno_ka <- as.data.frame(colData(vsd)[samps, "before_during_heatwave", drop = FALSE])
for (nm in names(anno_ka)) anno_ka[[nm]] <- droplevels(factor(anno_ka[[nm]]))
stopifnot(identical(rownames(anno_ka), colnames(cor_ka)))

pheatmap::pheatmap(
  cor_ka,
  annotation_col    = anno_ka,
  color             = viridisLite::viridis(255),
  border_color      = "black",
  cluster_rows      = TRUE,
  cluster_cols      = TRUE,
  show_rownames     = FALSE,
  show_colnames     = FALSE,
  main              = sprintf("Karitane — sample–sample correlation (n=%d)", length(samps)),
  legend            = TRUE
)
```


```{r}
# global fit once
dds$Location <- relevel(factor(dds$Location), "Akaroa")
dds$before_during_heatwave <- factor(dds$before_during_heatwave, c("Before","During"))
design(dds) <- ~ Location + before_during_heatwave + Location:before_during_heatwave
dds <- DESeq(dds)

# Akaroa = baseline, so its During vs Before is the main effect:
res_ak <- results(dds, name = "before_during_heatwave_During_vs_Before")
```
```{r Exporting results to CSV files, message=FALSE, warning=FALSE, include=FALSE}
# contrast: 400 vs 300 (so 300 is the reference)
res_df_ak <- as.data.frame(res_ak)
res_df_ak$gene <- rownames(res_df_ak)
res_df_ak$signif <- with(res_df_ak,
  ifelse(padj < 0.05 & log2FoldChange > 1,  "Up",
  ifelse(padj < 0.05 & log2FoldChange < -1, "Down", "NS")))

ggplot(res_df_ak, aes(log2FoldChange, -log10(padj), color = signif)) +
  geom_point(alpha = 0.7, size = 2) +
  scale_color_manual(values = c(Up="red", Down="blue", NS="grey70")) +
  geom_vline(xintercept = c(-1, 1), linetype="dashed") +
  geom_hline(yintercept = -log10(0.05), linetype="dashed") +
  labs(title="Akaroa: before_during_heatwave",
       x="log2 fold change before_during_heatwave", y="-log10 FDR") +
  theme_classic(base_size = 15)
```
``` {r code from josh , message=FALSE, warning=FALSE, include=FALSE}
# Subset to only Akaroa samples
dds_ha <- dds[, dds$Location == "Haast"]

# Drop the unused factor levels so only "300" and "400" remain
dds_ha$Location <- droplevels(dds_ha$Location)
dds_ha$before_during_heatwave     <- droplevels(dds_ha$before_during_heatwave)

# Make sure design is only Date (since we want 400 vs 300)
design(dds_ha) <- ~ before_during_heatwave

# Run DESeq
dds_ha <- DESeq(dds_ha)

# contrast: 400 vs 300 (so 300 is the reference)
res_ha <- results(dds_ha, contrast = c("before_during_heatwave","During", "Before"))

res_df_ha <- as.data.frame(res_ha)
res_df_ha$gene <- rownames(res_df_ha)
res_df_ha$signif <- with(res_df_ha,
  ifelse(padj < 0.05 & log2FoldChange > 1,  "Up",
  ifelse(padj < 0.05 & log2FoldChange < -1, "Down", "NS")))

ggplot(res_df_ha, aes(log2FoldChange, -log10(padj), color = signif)) +
  geom_point(alpha = 0.7, size = 2) +
  scale_color_manual(values = c(Up="red", Down="blue", NS="grey70")) +
  geom_vline(xintercept = c(-1, 1), linetype="dashed") +
  geom_hline(yintercept = -log10(0.05), linetype="dashed") +
  labs(title="Haast: before_during_heatwave",
       x="log2 fold change before_during_heatwave", y="-log10 FDR") +
  theme_classic(base_size = 15)
```
``` {r code from josh , message=FALSE, warning=FALSE, include=FALSE}
# Subset to only Karitane samples
dds_ka <- dds[, dds$Location == "Karitane"]

# Drop the unused factor levels so only "300" and "400" remain
dds_ka$Location <- droplevels(dds_ka$Location)
dds_ka$Date     <- droplevels(dds_ka$before_during_heatwave)

# Make sure design is only Date (since we want 400 vs 300)
design(dds_ka) <- ~ before_during_heatwave

# Run DESeq
dds_ka <- DESeq(dds_ka)

# contrast: 400 vs 300 (so 300 is the reference)
res_ka <- results(dds_ka, contrast = c("before_during_heatwave", "During", "Before"))

res_df_ka <- as.data.frame(res_ka)
res_df_ka$gene <- rownames(res_df_ka)
res_df_ka$signif <- with(res_df_ka,
  ifelse(padj < 0.05 & log2FoldChange > 1,  "Up",
  ifelse(padj < 0.05 & log2FoldChange < -1, "Down", "NS")))

ggplot(res_df_ka, aes(log2FoldChange, -log10(padj), color = signif)) +
  geom_point(alpha = 0.7, size = 2) +
  scale_color_manual(values = c(Up="red", Down="blue", NS="grey70")) +
  geom_vline(xintercept = c(-1, 1), linetype="dashed") +
  geom_hline(yintercept = -log10(0.05), linetype="dashed") +
  labs(title="Karitane: before_during_heatwave",
       x="log2 fold change before_during_heatwave", y="-log10 FDR") +
  theme_classic(base_size = 15)
```
```{r}
# ---- 0) Preconditions ----
stopifnot(exists("vsd"))                       # your VST object
stopifnot(file.exists("/projects/health_sciences/bms/biochemistry/kenny_group/Roseanna/Paua_sprng2024_sumr2025/Josh_test/GO:0007049_cell_cycle_genelist.txt"))

# ---- 1) Read the cell-cycle gene list (robust to header/no-header) ----
cc_try <- try(read.csv("/projects/health_sciences/bms/biochemistry/kenny_group/Roseanna/Paua_sprng2024_sumr2025/Josh_test/GO:0007049_cell_cycle_genelist.txt",
                       header = TRUE, stringsAsFactors = FALSE), silent = TRUE)

if (inherits(cc_try, "try-error") || ncol(cc_try) > 1L && !any(grepl("TRINITY_", cc_try[[1]][1], fixed=TRUE))) {
  # fallback: one ID per line
  cc_ids <- unique(readLines("/projects/health_sciences/bms/biochemistry/kenny_group/Roseanna/Paua_sprng2024_sumr2025/Josh_test/GO:0007049_cell_cycle_genelist.txt"))
  cell_cycle <- data.frame(gene = cc_ids, stringsAsFactors = FALSE)
} else {
  cell_cycle <- cc_try
  if (!"gene" %in% names(cell_cycle)) names(cell_cycle)[1] <- "gene"
  cell_cycle <- dplyr::distinct(cell_cycle, gene)
}

# ---- 2) Build metadata from vsd without duplicating SampleID ----
meta <- as.data.frame(colData(vsd))
if (!"SampleID" %in% names(meta)) {
  meta$SampleID <- rownames(meta)
} else {
  rownames(meta) <- meta$SampleID
}
meta <- meta[!duplicated(meta$SampleID), , drop = FALSE]

# ---- 3) Intersect the gene set with your VST matrix ----
genes_of_interest <- unique(cell_cycle$gene)
genes_in_vsd <- intersect(genes_of_interest, rownames(vsd))
message(sprintf("Cell-cycle genes provided: %d; present in VST: %d",
                length(genes_of_interest), length(genes_in_vsd)))
stopifnot(length(genes_in_vsd) > 0)

# ---- 4) Compute per-sample gene-set score: mean gene-wise z across the set ----
mat <- assay(vsd)[genes_in_vsd, , drop = FALSE]  # genes x samples
mat_z <- t(scale(t(mat)))                        # z-score each gene across samples
set_score <- colMeans(mat_z, na.rm = TRUE)       # one score per sample

# ---- 5) Assemble tidy frame and ensure factor ordering ----
df_score <- data.frame(
  SampleID = colnames(vsd),
  score    = set_score,
  stringsAsFactors = FALSE
) %>%
  left_join(meta, by = "SampleID")

if ("before_during_heatwave" %in% names(df_score)) {
  df_score$before_during_heatwave <- factor(df_score$before_during_heatwave,
                                            levels = c("Before","During"))
}
if ("Location" %in% names(df_score)) {
  df_score$Location <- factor(df_score$Location)
}

# ---- 6) Plot: Before vs During per Location ----
ggplot(df_score, aes(before_during_heatwave, score, fill = before_during_heatwave)) +
  geom_violin(trim = FALSE, alpha = 0.5) +
  geom_boxplot(width = 0.15, outlier.shape = NA, color = "black") +
  geom_jitter(width = 0.08, alpha = 0.7, size = 1.6) +
  facet_wrap(~ Location, nrow = 1) +
  labs(
    title    = "Cell-cycle gene set score by condition",
    subtitle = sprintf("Mean z-score across %d matched cell-cycle genes", length(genes_in_vsd)),
    x = NULL, y = "Mean gene-wise z-score"
  ) +
  theme_classic() +
  theme(legend.position = "none")

# ---- 7) (Optional) quick stats: does the score drop During? ----
if (all(c("Location","before_during_heatwave") %in% names(df_score))) {
  cat("\n== Global model: score ~ Location + before_during_heatwave ==\n")
  print(summary(lm(score ~ Location + before_during_heatwave, data = df_score)))

  cat("\n== Within-location models: score ~ before_during_heatwave ==\n")
  by(df_score, df_score$Location, function(d) {
    cat("\n-- Location:", as.character(unique(d$Location)), "--\n")
    print(summary(lm(score ~ before_during_heatwave, data = d)))
  })
}
```
```{r}
site <- "Karitane"                                 # change as needed
gene_list_file <- "/projects/health_sciences/bms/biochemistry/kenny_group/Roseanna/Paua_sprng2024_sumr2025/Josh_test/GO:0007049_cell_cycle_genelist.txt"

# ---- read gene list (header or one-per-line) ----
cc_try <- try(read.csv(gene_list_file, header=TRUE, stringsAsFactors=FALSE), silent=TRUE)
genes_of_interest <- if (inherits(cc_try,"try-error") || ncol(cc_try)>1L && !grepl("TRINITY_", cc_try[[1]][1], fixed=TRUE)) {
  unique(readLines(gene_list_file))
} else { if (!"gene" %in% names(cc_try)) names(cc_try)[1]<-"gene"; unique(cc_try$gene) }

stopifnot(exists("vsd"))
meta <- as.data.frame(colData(vsd))
stopifnot(all(c("Location","before_during_heatwave") %in% names(meta)))

samps <- rownames(meta)[meta$Location == site]
cond  <- droplevels(meta[samps, "before_during_heatwave", drop=TRUE])
if (!all(c("Before","During") %in% levels(cond))) stop("Site lacks both Before and During samples.")

genes <- intersect(genes_of_interest, rownames(vsd))
mat   <- assay(vsd)[genes, samps, drop=FALSE]

# per-gene effect on VST scale: Δ = mean(During) − mean(Before)
dVST <- rowMeans(mat[, cond=="During", drop=FALSE]) - rowMeans(mat[, cond=="Before", drop=FALSE])
df   <- data.frame(gene = genes, dVST = dVST, stringsAsFactors = FALSE)

# bootstrap CI for median
set.seed(1)
B <- 5000
med_boot <- replicate(B, median(sample(df$dVST, replace=TRUE), na.rm=TRUE))
med <- median(df$dVST, na.rm=TRUE)
ci  <- quantile(med_boot, c(0.025, 0.975), na.rm=TRUE)

# ECDF
ggplot(df, aes(dVST)) +
  stat_ecdf(geom="step", linewidth=0.9) +
  geom_vline(xintercept = 0, linetype="dashed", color="grey40") +
  geom_vline(xintercept = med, color="red") +
  annotate("rect", xmin = ci[1], xmax = ci[2], ymin = 0, ymax = 1,
           alpha = 0.08, fill = "red") +
  labs(title = sprintf("%s — Cell cycle per-gene effect", site),
       subtitle = sprintf("ΔVST = mean(During) − mean(Before); median = %.3f (95%% CI %.3f–%.3f)",
                          med, ci[1], ci[2]),
       x = "Per-gene ΔVST", y = "ECDF") +
  theme_classic()

```
```{r}
avgVST <- rowMeans(mat, na.rm=TRUE)    # per-gene average VST across site
df$avgVST <- avgVST[match(df$gene, names(avgVST))]

ggplot(df, aes(avgVST, dVST)) +
  geom_point(alpha=0.25, size=0.9) +
  geom_smooth(method="loess", se=TRUE, span=0.6, linewidth=1.0) +
  geom_hline(yintercept = 0, linetype="dashed", color="grey40") +
  labs(title = sprintf("%s — MA-style plot (cell cycle)", site),
       x = "Mean VST (Before+During)", y = "ΔVST (During − Before)") +
  theme_classic()
```
```{r}
site <- "Karitane"                                 # change as needed
gene_list_file <- "/projects/health_sciences/bms/biochemistry/kenny_group/Roseanna/Paua_sprng2024_sumr2025/Josh_test/GO:0007049_cell_cycle_genelist.txt"

# ---- read gene list (header or one-per-line) ----
cc_try <- try(read.csv(gene_list_file, header=TRUE, stringsAsFactors=FALSE), silent=TRUE)
genes_of_interest <- if (inherits(cc_try,"try-error") || ncol(cc_try)>1L && !grepl("TRINITY_", cc_try[[1]][1], fixed=TRUE)) {
  unique(readLines(gene_list_file))
} else { if (!"gene" %in% names(cc_try)) names(cc_try)[1]<-"gene"; unique(cc_try$gene) }

stopifnot(exists("vsd"))
meta <- as.data.frame(colData(vsd))
stopifnot(all(c("Location","before_during_heatwave") %in% names(meta)))

samps <- rownames(meta)[meta$Location == site]
cond  <- droplevels(meta[samps, "before_during_heatwave", drop=TRUE])
suppressPackageStartupMessages({
  library(pheatmap)
  library(viridisLite)
})

topN <- min(150L, nrow(df))
top_genes <- df$gene[order(abs(df$dVST), decreasing = TRUE)][seq_len(topN)]

ann <- meta[samps, c("before_during_heatwave"), drop = FALSE]
ann$before_during_heatwave <- droplevels(factor(ann$before_during_heatwave))

main_title <- sprintf("%s — Cell cycle (top %d by |ΔVST|), row-z", site, topN)

pheatmap(
  assay(vsd)[top_genes, samps, drop = FALSE],
  scale = "row",
  color = colorRampPalette(c("blue", "white", "red"))(255),
  annotation_col = ann,
  show_rownames = FALSE,
  main = main_title,
  clustering_distance_rows = "correlation",
  clustering_distance_cols = "correlation"
)
```
```{r}
site <- "Haast"                                 # change as needed
# ---- read gene list (header or one-per-line) ----
cc_try <- try(read.csv(gene_list_file, header=TRUE, stringsAsFactors=FALSE), silent=TRUE)
genes_of_interest <- if (inherits(cc_try,"try-error") || ncol(cc_try)>1L && !grepl("TRINITY_", cc_try[[1]][1], fixed=TRUE)) {
  unique(readLines(gene_list_file))
} else { if (!"gene" %in% names(cc_try)) names(cc_try)[1]<-"gene"; unique(cc_try$gene) }

stopifnot(exists("vsd"))
meta <- as.data.frame(colData(vsd))
stopifnot(all(c("Location","before_during_heatwave") %in% names(meta)))

samps <- rownames(meta)[meta$Location == site]
cond  <- droplevels(meta[samps, "before_during_heatwave", drop=TRUE])
suppressPackageStartupMessages({
  library(pheatmap)
  library(viridisLite)
})

topN <- min(150L, nrow(df))
top_genes <- df$gene[order(abs(df$dVST), decreasing = TRUE)][seq_len(topN)]

ann <- meta[samps, c("before_during_heatwave"), drop = FALSE]
ann$before_during_heatwave <- droplevels(factor(ann$before_during_heatwave))

main_title <- sprintf("%s — Cell cycle (top %d by |ΔVST|), row-z", site, topN)

pheatmap(
  assay(vsd)[top_genes, samps, drop = FALSE],
  scale = "row",
  color = colorRampPalette(c("blue", "white", "red"))(255),
  annotation_col = ann,
  show_rownames = FALSE,
  main = main_title,
  clustering_distance_rows = "correlation",
  clustering_distance_cols = "correlation"
)
```
```{r}
site <- "Akaroa"                                 # change as needed
# ---- read gene list (header or one-per-line) ----
cc_try <- try(read.csv(gene_list_file, header=TRUE, stringsAsFactors=FALSE), silent=TRUE)
genes_of_interest <- if (inherits(cc_try,"try-error") || ncol(cc_try)>1L && !grepl("TRINITY_", cc_try[[1]][1], fixed=TRUE)) {
  unique(readLines(gene_list_file))
} else { if (!"gene" %in% names(cc_try)) names(cc_try)[1]<-"gene"; unique(cc_try$gene) }

stopifnot(exists("vsd"))
meta <- as.data.frame(colData(vsd))
stopifnot(all(c("Location","before_during_heatwave") %in% names(meta)))

samps <- rownames(meta)[meta$Location == site]
cond  <- droplevels(meta[samps, "before_during_heatwave", drop=TRUE])
suppressPackageStartupMessages({
  library(pheatmap)
  library(viridisLite)
})

topN <- min(150L, nrow(df))
top_genes <- df$gene[order(abs(df$dVST), decreasing = TRUE)][seq_len(topN)]

ann <- meta[samps, c("before_during_heatwave"), drop = FALSE]
ann$before_during_heatwave <- droplevels(factor(ann$before_during_heatwave))

main_title <- sprintf("%s — Cell cycle (top %d by |ΔVST|), row-z", site, topN)

pheatmap(
  assay(vsd)[top_genes, samps, drop = FALSE],
  scale = "row",
  color = colorRampPalette(c("blue", "white", "red"))(255),
  annotation_col = ann,
  show_rownames = FALSE,
  main = main_title,
  clustering_distance_rows = "correlation",
  clustering_distance_cols = "correlation"
)
```
```{r}
site <- "Karitane"   # <-- change to "Haast" or "Karitane"
# subset samples for this site
samps <- colnames(vsd)[colData(vsd)$Location == site]

# calculate variance only within these samples
rv <- rowVars(assay(vsd)[, samps, drop = FALSE])
top_genes <- order(rv, decreasing = TRUE)[1:150]

# annotations for just these samples
ann <- as.data.frame(colData(vsd)[samps, "before_during_heatwave", drop = FALSE])
ann$before_during_heatwave <- droplevels(factor(ann$before_during_heatwave))

main_title <- sprintf("%s — Top 150 most variable genes (row-z)", site)

# plot heatmap
pheatmap(
  assay(vsd)[top_genes, samps, drop = FALSE],
  scale = "row",
  color = colorRampPalette(c("blue", "white", "red"))(255),
  annotation_col = ann,
  show_rownames = FALSE,
  main = main_title,
  clustering_distance_rows = "correlation",
  clustering_distance_cols = "correlation"
)
```
```{r}
write.csv(res_df_ha,
          file = "Haast_DESeq2_resultscpmsalmon.csv",
          row.names = FALSE)

res_sig <- subset(res_df_ha,log2FoldChange >= 1 & padj <0.05)
write.csv(res_sig,
          file = "Haast_DESeq2_upsigsalmon.csv",
          row.names = FALSE)

res_sigd <- subset(res_df_ha,log2FoldChange >= -1 & padj <0.05)
write.csv(res_sigd,
          file = "Haast_DESeq2_downsigsalmon.csv",
          row.names = FALSE)

res_sigd <- subset(res_df_ka,log2FoldChange >= -1 & padj <0.05)
write.csv(res_sigd,
          file = "Karitane_DESeq2_downsigsalmon.csv",
          row.names = FALSE)
res_sigd <- subset(res_df_ak,log2FoldChange >= -1 & padj <0.05)
write.csv(res_sigd,
          file = "Akaroa_DESeq2_downsigsalmon.csv",
          row.names = FALSE)
```

```{r}
## --- Setup ---
# thresholds
alpha_cut <- 0.05
lfc_cut   <- 1

# --- Filter functions (no mapping needed) ---
sig_up <- function(df) {
  rownames(df)[!is.na(df$padj) & df$padj < alpha_cut & df$log2FoldChange >  lfc_cut]
}

sig_down <- function(df) {
  rownames(df)[!is.na(df$padj) & df$padj < alpha_cut & df$log2FoldChange < -lfc_cut]
}

# --- Build sets ---
up_sets <- list(
  Akaroa   = sig_up(res_df_ak),
  Haast    = sig_up(res_df_ha),
  Karitane = sig_up(res_df_ka)
)

down_sets <- list(
  Akaroa   = sig_down(res_df_ak),
  Haast    = sig_down(res_df_ha),
  Karitane = sig_down(res_df_ka)
)

# --- Venn: UP-regulated ---
plot_up <- ggVennDiagram(up_sets, label = "count") +
  labs(title = "Significantly Upregulated (padj < 0.05, log2FC > 1)") +
  theme_classic()
print(plot_up)

# --- Venn: DOWN-regulated ---
plot_down <- ggVennDiagram(down_sets, label = "count") +
  labs(title = "Significantly Downregulated (padj < 0.05, log2FC < -1)") +
  theme_classic()
print(plot_down)
```
```{r}
# Load annotated table
annot_df <- read_csv("kuku_annotation_merged_deduplicated20052025.csv")
# Rename gene column for joining
annot_df <- annot_df %>%
  rename(gene = Geneid)
# Merge annotations into full DESeq results
res_df_hpf0vs0.5_annot <- res_df_hpf0vs0.5 %>%
  left_join(annot_df, by = "gene") %>%
  mutate(
    log2FoldChange = ifelse(is.na(log2FoldChange), 0, log2FoldChange),
    padj = ifelse(is.na(padj), 1, padj),
    significant = padj < 0.05 & abs(log2FoldChange) > 0.58
  )

# Add label column for top 20 most significant genes
res_df_hpf0vs0.5_annot$delabel <- NA
top_20 <- order(res_df_hpf0vs0.5_annot$padj, na.last = NA)[1:20]
res_df_hpf0vs0.5_annot$delabel[top_20] <- res_df_hpf0vs0.5_annot$Preferred_name[top_20]
```
